{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sweksha/coursera/local/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import statsmodels.api as sm\n",
    "from pandas.core import datetools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv('train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputation(data):\n",
    "    df_age= data['Age']\n",
    "    mean_df = np.mean(df_age)\n",
    "    data['Age'] = data['Age'].fillna(mean_df)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_normalize(features):\n",
    "    ''' Feature Normalization When features differ by orders of magnitude,\n",
    "    first performing feature scaling can make gradient descent converge \n",
    "    much more quickly'''\n",
    "    sd = np.std(features, axis=0)\n",
    "    mean = np.mean(features, axis=0)\n",
    "    x_norm = (features - mean)/sd\n",
    "    return x_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(features, values, theta):\n",
    "    \"\"\"\n",
    "    Compute the cost of a list of parameters, theta, given a list of features \n",
    "    (input data points) and values (output data points).\n",
    "    \"\"\"\n",
    "    m = len(values)\n",
    "    sum_of_square_errors = np.square(np.dot(features, theta) - values).sum()\n",
    "    cost = sum_of_square_errors / (2*m)\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(features, values, theta, alpha, num_iterations):\n",
    "    \"\"\"\n",
    "    Perform gradient descent given a data set with an arbitrary number of features.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    m = len(values)\n",
    "    cost_history = []\n",
    "    for i in range(num_iterations):\n",
    "        prediction_values = np.dot(features, theta)\n",
    "        theta = theta - alpha/m * np.dot(np.transpose(features), (prediction_values-values))\n",
    "        cost = compute_cost(features, values, theta)\n",
    "        cost_history.append(cost)\n",
    "    return theta, pandas.Series(cost_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_r_squared(data, predictions):\n",
    "    # Calculates the coefficient of determination, R^2, for the model that produced \n",
    "\n",
    "    mean = np.mean(data)\n",
    "    sum_of_square_errors = np.square(data - predictions).sum()\n",
    "    sum_of_square_data =  np.square(data - mean).sum()\n",
    "    r_squared = 1- sum_of_square_errors/sum_of_square_data\n",
    "    return r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_grad_dic(dfa):\n",
    "    df = imputation(dfa)\n",
    "    \n",
    "    # Select Features (try different features!)\n",
    "    features = df[['Pclass', 'Age', 'SibSp', 'Parch']]\n",
    "    \n",
    "    \n",
    "    # Add date to features using dummy variables\n",
    "    dummy_units = pandas.get_dummies(df['Sex'], prefix='sex')\n",
    "    features = features.join(dummy_units)\n",
    "    #print dummy_units\n",
    "    # Values\n",
    "    values = df['Survived']\n",
    "    m = len(values)\n",
    "     \n",
    "    features = features_normalize(features)\n",
    "    add_col = features.insert(0, 'x0', 1)\n",
    "#    features['ones'] = np.ones(m) # Add a column of 1s (y intercept)\n",
    "    \n",
    "    # Convert features and values to numpy arrays\n",
    "    features_array = np.array(features)\n",
    "    values_array = np.array(values)\n",
    "\n",
    "    # Set values for alpha, number of iterations.\n",
    "    alpha = 0.05 # please feel free to change this value\n",
    "    num_iterations = 100 # please feel free to change this value\n",
    "    \n",
    "    # Initialize theta, perform gradient descent\n",
    "    theta_gradient_descent = np.zeros(len(features.columns))\n",
    "    theta_gradient_descent, cost_history = gradient_descent(features_array, \n",
    "                                                            values_array, \n",
    "                                                            theta_gradient_descent, \n",
    "                                                            alpha, \n",
    "                                                            num_iterations)\n",
    " \n",
    "    \n",
    "    predictions = np.dot(features_array, theta_gradient_descent)\n",
    "    r_squared = compute_r_squared(values_array, predictions)\n",
    "    data_pred = pandas.DataFrame(data = predictions)\n",
    "    feature_array = pandas.DataFrame(data = features_array)\n",
    "    y = data_pred.round(decimals=0)\n",
    "    x = y.astype(int)\n",
    "    return x, theta_gradient_descent, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cost_history(df):\n",
    "    alpha = 0.05 # please feel free to change this value\n",
    "    x, theta_gradient_descent, cost_history = prediction_grad_dic(df)\n",
    "    cost_df = pandas.DataFrame({\n",
    "        'Cost_History': cost_history,\n",
    "        'Iteration': range(len(cost_history))})\n",
    "    plt.figure()\n",
    "    plt.plot(cost_df['Cost_History'], cost_df['Iteration'])\n",
    "   \n",
    "    plt.title('Cost_History vs. Iteration for alpha = %.3f' % alpha)\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Cost_History')   \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
